---
title: Bayesian halo
description: TODO
date: "`r Sys.Date()`"
author: Giuseppe Tinti Tomio
output:
    distill::distill_article:
        toc: true
repository_url: https://github.com/GiuseppeTT/bayesian-halo
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
    echo = FALSE,
    warning = FALSE,
    message = FALSE
)
```

```{r libraries}
library(tidyverse)
library(gt)
library(targets)
```

```{r sources}
source("R/constants.R")
```

# Too long, didn't read

TODO.

# Introduction

If you are like me, you have been playing [Halo Infinite](https://www.xbox.com/games/halo-infinite) a lot in the past weeks. One game mode that I particularly like is Big Team Battle Slayer (BTBS) in which 2 teams of 16 players face each other in a battlefield. Each time one player of team blue defeats a player of team red, team blue earns a point. The first team to achieve 100 points wins the game. If no team hits 100 points by the 15 minutes mark, the team with the biggest score wins.

Now if you are really like me, you have also been wondering about how to statistically model the game. Specifically, I was interested in calculating the probability of my team winning given the current score. Intuitively, I know that there is a 50%-50% chance of winning when the game starts. If the score is 20 - 10 for my team, I also expect to have a higher although not extreme probability of winning. But what about when the score is 90 - 80? From my experience this game is a certain win, but how should I quantify this probability? This is the question that my work sets to answer using bayesian statistics.

<!--
    The report is divided into sections. Section [Dataset] describes the dataset used and Section [Exploratory data analysis] presents an exploratory analysis of its content to understand statistical properties of the game data. Based on this exploratory analysis, Section [Model] defines a Bayesian model for the data and Section [Prior model analysis] shows a synthetic dataset for the given prior values. Finally, Section [Results] shows the results obtained when fitting the model to the full data and [Conclusion] finishes the report with the final conclusions.
-->

# Dataset

To answer the question proposed, I selected two matches of Halo BTBS from YouTube and manually filled two spreadsheets with game statistics. The first game is available at https://youtu.be/cANMWiYTD84 and defines the train dataset. It was used to gain some quantitative knowledge about this type of data, propose a model and check valid values for a prior distribution. The second game is available at https://youtu.be/kuH9nhdzt64 and defines the test dataset. It was used to fit the proposed model in a novel dataset to check the model's performance.

Each dataset is composed of three variables (columns). They are:

- **time:** Time at which the score was recorded.
- **blue:** Score of team blue at the time. Team blue is the team of the player who recorded the gameplay.
- **red:** Score of team red at the time. Team red is the enemy team of the player who recorded the gameplay.

Due to the way the data was recorded, there are a few concerns which could not be addressed. They are:

- The data was extracted from a gameplay available at YouTube and, therefore, might not be representative. This is because people tend to publish only games where they (and therefore their team) had a good performance.
- The data was manually extracted, which means that there may be a difference between the recorded and the actual time of each score point. Besides, there are times in which the scoreboard is not visible or is only partially visible which might have impacted the annotated data.
- The maximum time resolution is 1 second as it is constrained by the in-game time resolution, obtained from the scoreboard timer.

All things considered, that data should be enough for developing a proof of concept.

# Exploratory data analysis

In the exploratory analysis, I demonstrate how the following properties about the data hold true, at least to an approximate extent.

- **Independent points** : Each point is earned independently from the other points.
- **Constant point rate** : The average time between points is constant throughout the game. The average differs between the teams.
- **Exponentially distributed** : The time between points follows an exponential distribution. The distribution differs between the teams.

We begin the analysis with Figure \@ref(fig:train-observed-score-plot) which summarizes the data. It shows the score progression for both teams as observed in the train dataset. Besides the clear win for team blue, a pattern stands out. The score trajectories are linear which suggests that the teams earn points at a constant rate.

```{r train-observed-score-plot, fig.cap = "Score progression for both teams. As observed in the train dataset."}
tar_read(observed_score_plot)
```

To better explore the point rate, we refer to Figure \@ref(fig:train-observed-tbp-vs-score-plot). It shows the time between points (TBP) for each team as a function of score. As it can be seen by the regression curves, the average TBP is constant throughout the game.

<!--
Perhaps the only exception is the first score point which took roughly 30 seconds for both teams. This is due to the fact that the players start at their bases and must walk to the middle of the battlefield in the start of the game.
-->

```{r train-observed-tbp-vs-score-plot, fig.cap = "Time between points (TBP) for each team as a function of score. As observed in the train dataset."}
tar_read(observed_tbp_vs_score_plot)
```

Still about the time between points, Figure \@ref(fig:train-observed-tbp-plot) plots the estimated distribution for each team. The estimated distributions have an exponential decay which favors an exponential distribution.

```{r train-observed-tbp-plot, fig.cap = "Estimated TBP distribution for each team. As observed in the train dataset."}
tar_read(observed_tbp_plot)
```

To evaluate the independence between points, Figure \@ref(fig:train-observed-tbp-vs-lag-tbp-plot) shows the TBP vs previous TBP for each team. Taking into account the estimation error, the regression line is reasonably constant. This means that there is little dependence between points in each tam.

```{r train-observed-tbp-vs-lag-tbp-plot, fig.cap = "Time between points (TBP) for each team as a function of lag TBP. As observed in the train dataset."}
tar_read(observed_tbp_vs_lag_tbp_plot)
```

```{r train-permuted-tbp-vs-lag-tbp-plot, fig.cap = "Time between points (TBP) for each team as a function of lag TBP. As observed in the train dataset with shuffled TBP."}
# tar_read(permuted_tbp_vs_lag_tbp_plot)
```

Finally, look at the relation between the teams to inspect for any correlaction between them. Figure BLAH.

# Model

Accounting for all the discoveries made in the exploratory data analysis, I came up with the following bayesian model.

```R
# Part 1: Data
point_time[blue][1], ..., point_time[blue][blue_last_score]
point_time[red][1], ..., point_time[red][red_last_score]

# Part 2: Transformed data
tbp[blue][i] = point_time[blue][i] - point_time[blue][i - 1]
tbp[red][j] = point_time[red][j] - point_time[red][j - 1]

# Part 3: Prior
MAX_SCORE = 100
MAX_TIME = 15
mean_rate_of_rates = MAX_SCORE / (2 / 3 * MAX_TIME)
rate_of_rates = 1 / mean_rate_of_rates

# Part 4: Parameters
point_rate[blue] ~ Exponential(rate_of_rates)
point_rate[red] ~ Exponential(rate_of_rates)

# Part 5: Likelihood
tbp[blue][i] ~ Exponential(point_rate[blue])
tbp[red][j] ~ Exponential(point_rate[red])
```

Part 1 and 2 describe the given data, which is the time at which each point was earned by each team, and how to calculate the time between points from it. As for the other parts, it is easier to explain in a backward manner.

Part 5 BLAH.

Part 4 BLAH.

Part 3 BLAH.

<!--
It begins by assuming that each team has a different point rate. Namely, `point_rate[blue]` and `point_rate[red]`. This means that independently from its own history and team red's history, team blue makes `point_rate[blue]` points per minute on average.

Furthermore, the model assumes that, given the points rates, blah blah exponential distribution for TBP.

Finally, the prior blah blah blah.
-->

<!-- Explain the thought process behind the prior value. That is, on average 10 minutes a game, cover games from blah to blah. Exponential distribution maximizes entropy-->

# Prior model analysis

Before fitting the model to the data, it is interesting to check if the selected prior is appropriate. To do that, we can simulate data from the model using only the prior information. That is, without providing data to the model. Figure \@ref(fig:prior-score-plot) summarizes the simulated data. It shows the score progression for a hypothetical team as simulated from the prior model.

```{r}
# tar_read(prior_model_rate_plot)
```

```{r prior-score-plot, fig.cap = "Score progression for a hypothetical team. As simulated from the prior model."}
tar_read(prior_model_score_plot)
```

```{r}
# tar_read(prior_model_tbp_vs_score_plot)
```

```{r}
# tar_read(prior_model_tbp_plot)
```

# Results

## Train dataset

```{r}
tar_read(train_model_rate_table) %>%
    select(
        rate,
        .value,
        .lower,
        .upper
    ) %>%
    gt(caption = "TODO") %>%
    cols_align("left", where(is.factor)) %>%
    fmt_number(where(is.numeric), decimals = DECIMALS) %>%
    cols_merge(c(.lower, .upper),pattern = "[{1}, {2}]") %>%
    cols_label(
        rate = "Point rate",
        .value = "Median",
        .lower = "95% HDCI"
    )
```

```{r}
#tar_read(train_model_rate_plot)
```

```{r}
tar_read(train_model_score_plot)
```

```{r}
# tar_read(train_model_tbp_vs_score_plot)
```

```{r}
# tar_read(train_model_tbp_plot)
```

## Test dataset

```{r}
tar_read(test_model_rate_table) %>%
    select(
        rate,
        .value,
        .lower,
        .upper
    ) %>%
    gt(caption = "TODO") %>%
    cols_align("left", where(is.factor)) %>%
    fmt_number(where(is.numeric), decimals = DECIMALS) %>%
    cols_merge(c(.lower, .upper),pattern = "[{1}, {2}]") %>%
    cols_label(
        rate = "Point rate",
        .value = "Median",
        .lower = "95% HDCI"
    )
```

```{r}
# tar_read(test_model_rate_plot)
```

```{r}
tar_read(test_model_score_plot)
```

```{r}
# tar_read(test_model_tbp_vs_score_plot)
```

```{r}
# tar_read(test_model_tbp_plot)
```

# Conclusion

TODO
